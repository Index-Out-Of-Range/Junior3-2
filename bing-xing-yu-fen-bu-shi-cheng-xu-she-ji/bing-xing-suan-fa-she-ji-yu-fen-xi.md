## 并行算法设计

* 任务分解、数据依赖、竞争条件
* 数据并行
* 其他任务划分方法



* 假定已有求解问题的串行算法，将其改为并行版本
  * 并不一定是最好的策略——有些情况下，最优并行算法与最优串行算法完全没有关系 
  * 但很有用，我们很熟悉串行算法，很多时候是切实可行的方法 
* 并行算法与体系结构紧密相关！

#### 设计一个并行算法

* 计算任务的分解
  * 如何将并行计算工作分解，交由众多进程/线程并发执行
* 保持依赖关系
  * 计算结果与串行算法保持一致
* 额外开销
  * 有多种类型的开销，要尽量降低

#### 竞争条件与数据依赖

* **执行结果**依赖于两个或更多事件的时序， 则存在竞争条件（race condition） 
* **数据依赖**（data dependence）就是两个内 存操作的序，为了保证结果的正确性， 必须保持这个序
* **同步**（synchronization）用来将多个线程 的执行串行化，或是将并发数据访问串 行化



#### 一个简单的例子

* 计算n个值并求他们的和
* 串行算法：



```
sum = 0; 
for (i = 0; i &lt; n; i++) { 
    x = Compute next value(. . .); 
    sum += x; 
}
```


* 并行算法？

###### 版本1：计算任务划分
*  假定每个核心计算连续n/t个元素的部分和（t为线程数 或处理器数）
* 例子：n=24，t=8 
![](/images/并行/2019-04-10_111421.png)


```
int block_length_per_thread = n/t;    
int start = id * block_length_per_thread;    
for (i=start; i<start+block_length_per_thread; i++)  {           
    x = Compute_next_value(…); 
    sum += x; 
}
```

* 发生了什么？
  * 循环步之间的求和运算存在依赖 → 线程间依赖 
    * 但可以重排顺序，因为加法运算满足结合律 
  * 取数-加法-存结果必须是原子操作，以保持结果 与串行执行一致 
  * 定义 
    * **原子性**（atomicity）：一组操作要么全部执行要么全不执行，则称其是原子的。即，不会得到部分执行的结果。 
    * **互斥**（mutual exclusion）：任何时刻都只有一个线程在执行

###### 版本2：加锁 
* 插入互斥（mutex），保证任何时刻只有一个线程读数-加法-存结果——原子操作


```
int block_length_per_thread = n/t;    
mutex m; 
int start = id * block_length_per_thread;    
for (i=start; i<start+block_length_per_thread; i++)  {           
    my_x = Compute_next_value(…); 
    mutex_lock(m);       
    sum += my_x; mutex_unlock(m);     
}
```

> 已经是正确的了，但还不够好


###### 版本3：粗粒度
* 在将局部和加到全局和时才加锁 


```
int block_length_per_thread = n/t;    
mutex m; 
int my_sum; 
int start = id * block_length_per_thread;    
for (i=start; i<start+block_length_per_thread; i++)  {           
    my_x = Compute_next_value(…); 
    my_sum += my_x; 
} 
mutex_lock(m);       
sum += my_sum; mutex_unlock(m);   
```

###### 版本4：消除锁
* “主”线程完成部分和相加 


```
int block_length_per_thread = n/t;    
mutex m; 
shared my_sum[t]; 
int start = id * block_length_per_thread;    
for (i=start; i<start+block_length_per_thread; i++)  {           
    my_x = Compute_next_value(…); 
    my_sum[id] += my_x; 
} 
if (id == 0) {// 主线程 
    sum = my_sum[0]; 
    for (i=1; i<t; i++) 
        sum += my_sum[i]; 
} 

```
> 不正确

* 同步方法：障碍
  * 如果主线程开始计算全局和的时候其他线程还未完成计算，就会得到不正确的结果 
  * 如何强制主线程等待其他线程完成之后再进行全局和计算呢？
  * 定义 
    * 障碍（barrier）阻塞线程继续执行，在此程序点等待，直到所有参与线程都到达障碍点才继续执行 
    * 障碍如何实现？

###### 版本5：消除锁，但增加障碍


```
int block_length_per_thread = n/t;   
mutex m; 
shared my_sum[t]; 
int start = id * block_length_per_thread;    
for (i=start; i<start+block_length_per_thread; i++)  {           
    my_x = Compute_next_value(…); 
    my_sum[t] += x; 
} 
Synchronize_cores(); // 所有参与线程都设置障碍 
if (id == 0) { // 主线程 
    sum = my_sum[0]; 
    for (i=1; i<t; i++) 
        sum += my_sum[t]; 
} 
```



> 现在正确了！

###### 版本6：多核并行求全局和
![](/images/并行/2019-04-10_112802.png)

###### 求和例子的总结
* 求和计算有竞争条件和数据依赖 
* 使用mutex和障碍进行同步保证正确结果 
* 更多地进行本地运算，以提高线程间并行计算的粒度 
* 在这个例子中看到了哪些**额外开销**？ 
  * 分配计算任务的额外代码 
  * 锁开销：加锁/解锁操作本身开销和线程间竞争导致的空闲等待 
  * 负载不均
  
#### 如何设计并行程序
* 任务并行 
  * 将求解问题的计算分解为任务，分配给多个核心
* 数据并行 
  * 将求解问题涉及的数据划分给多个核心 
  * 每个核心对不同数据进行相似的计算

###### 教授P批改试卷：15道题 300份试卷
教授P有三位助教
  * 工作分配——数据划分
  ![](/images/并行/2019-04-10_113717.png)
  * 工作分配——任务划分
  ![](/images/并行/2019-04-10_113727.png)
  
###### 商品购买频率统计
![](/images/并行/2019-04-10_114932.png)
> 已知用户购物列表T，商品组合列表I ➔ 查询商品组合的购买频率

* 划分输出数据
  * 每种组合购买频率的计算是无关的 
  * I划分为若干部分，每部分的查询→任务
  ![](/images/并行/2019-04-10_115039.png)
  
* 划分输入数据
![](/images/并行/2019-04-10_115053.png)
> 结果组合：两个频率列表需相加

* 同时划分输入输出数据
![](/images/并行/2019-04-10_115212.png)

#### 其他任务划分方法
###### 搜索分解
* 15-数码问题
![](/images/并行/2019-04-10_120235.png)
* 解法 
  * 搜索空间组织为树结构 
    * 根节点：初始格局 
    * 节点A的孩子节点 
      * 格局A的后继格局，2～4个 
      * 格局A中空格与相邻位置交换的结果
* 先串行生成一定规模的搜索树 
* 任务分解——对得到的搜索树，以每个叶节点为根的子树的搜索工作作为一个任务 
* 任务协调——某个任务（子树）找到解，应通知其他任务（子树）停止搜索

###### 15数码任务分解图示
![](/images/并行/2019-04-10_122306.png)
* 与数据分解的区别
  * 数据分解：每个任务的计算工作的结果对最终结果都是有用的，都要全部做完 
  * 搜索分解：一旦一个任务找到解，全部任务即可停止，工作量可能大于，也可能小于串行算法
  ![](/images/并行/2019-04-10_122400.png)
  
###### 更多任务分解例：数据库查询
* 汽车数据库，进行复杂的组合查询： 

`Model=“Civic” AND Year=“2001” AND (Color=“Green” OR Color=“White”)`
![](/images/并行/2019-04-10_140641.png)

* 一种任务分解方法
![](/images/并行/2019-04-10_140911.png)

* 另一种任务分解
![](/images/并行/2019-04-10_140924.png)

* Ian Foster的方法学
![](/images/并行/2019-04-10_140941.png)

## 并行算法分析

#### 基本指标

* 串行算法评价：算法时间复杂度表示为输入规模的函数
* 并行算法评价：除了输入规模之外，还应考虑处理器数目、处理器相对运算速度、通信速度

* 评价标准

  * 运行时间
  * 加速比：并行算法比串行算法快多少？
    * 很多串行算法，选哪一个？

#### 并行程序设计的复杂性

* 足够的并发度（Amdahl定律）
* 并发力度
  * 独立的计算任务的大小
* 局部性
  * 对临近的数据进行计算
* 负载均衡
  * 处理器的工作量相近
* 协调和同步
  * 谁负责？处理频率

#### 并行算法额外开销
* 除了串行算法要做的之外的工作 
* 进程间通信：最大开销，大部分并行算法都需要 
* 进程空闲：负载不均、同步操作、不能并行化的部分 
* 额外计算 
  * 最优串行算法难以并行化，将很差的串行算法并行化，并行算法计算量>最优串行算法 
  * 最优串行算法并行化也会产生额外计算：并行快速傅立叶变换，旋转因子的重复计算
  ![](/images/并行/2019-04-10_150839.png)

#### 性能评价标准
* 运行时间 
  * 串行算法：TS，算法开始到结束的时间流逝 
  * 并行算法：TP，并行算法开始到最后一个进程结束所经历时间 
* 并行算法总额外开销 
  `To=pTP – TS`
* 加速比 
  `S=TS/TP`
  
* 例1：n个数相加，n个进程
![](/images/并行/2019-04-10_151157.png)
![](/images/并行/2019-04-10_151208.png)

* 初始，每个进程保存1个数； 最终由1个进程保存累加和 
* 树形结构，logn个步骤 
每个步骤进行一次加法：tc 和一个机器字的传输：ts+tw ➔TP=Q(logn) ➔S=Q(n/logn)


#### cache引起的超线性加速

* 2个处理器的并行系统，问题规模W
* 每个处理器由cache 64KB，命中率80%，cache延迟2ns，DRAM100ns，平均访问时间

> 2 \* 0.8 + 100 \* 0.2 = 21.6 ns

* 若
* #### 搜索分解导致超线性

### 可扩展性

#### 效率

* 理想并行算法，S=p
* 难实现，不是100%的时间都用于有效计算
* 求和例子，部分时间处理器处于空闲
* 效率：度量有效计算时间

#### 代价

* 并行算法运行时间 \* 处理器数量
* 所有处理器用来求解问题的时间总和
* E = Ts/cost,
  * p = 1时，cost = Ts
* 代价最优：代价与最优串行算法运行时间渐进相等——E= θ\(1\)

#### 代价最优

#### 非代价最优算法的性能

#### 



